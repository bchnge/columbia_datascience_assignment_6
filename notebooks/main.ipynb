{
 "metadata": {
  "name": "main"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import movie_reviews\n",
      "import nltk\n",
      "import random\n",
      "\n",
      "from homework_06.src.tagger import document_features\n",
      "import homework_06.src.classifier as cl\n",
      "import homework_06.src.tagger as tg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main():\n",
      "    #get the movie data\n",
      "    movie_data = getMovieData()\n",
      "    #shuffle it up\n",
      "    random.shuffle(movie_data)\n",
      "    #break up into test and train\n",
      "    test_data, train_data = movie_data[:len(movie_data)/2],  movie_data[len(movie_data)/2:]\n",
      "\n",
      "\n",
      "    #####From here on it's up to you how you want to tag and classify the reviews\n",
      "\n",
      "      # First, determine set of words to use for features. Consider using getTopwords\n",
      "    \n",
      "    pos_reviews = [sent[0] for sent in train_data if sent[1]=='pos']\n",
      "    neg_reviews = [sent[0] for sent in train_data if sent[1]=='neg']\n",
      "    \n",
      "    # Take out all adjectives\n",
      "    tagged_pos = tg.posTagger(pos_reviews[0:50], pos_type = 'JJ')\n",
      "    tagged_neg = tg.posTagger(neg_reviews[0:50], pos_type = 'JJ')\n",
      "\n",
      "    pos_adj = [tag[0] for tag in tagged_pos]\n",
      "    neg_adj = [tag[0] for tag in tagged_neg]\n",
      "    \n",
      "    pos_adj = tg.getTopWords(pos_adj,0.1)\n",
      "    neg_adj = tg.getTopWords(neg_adj,0.1)\n",
      "    \n",
      "\n",
      "    tagged_pos_final = [tag for tag in tagged_pos if tag[0] in pos_adj]\n",
      "    tagged_neg_final = [tag for tag in tagged_neg if tag[0] in neg_adj]\n",
      "    \n",
      "    tagged_features = list(set(tagged_pos_final).union(set(tagged_neg_final))) \n",
      "    tagged_features = list(set(tagged_features))\n",
      "    \n",
      "        \n",
      "    docData = []\n",
      "    for review in train_data:\n",
      "        review_features = document_features(review[0], tagged_features)\n",
      "        review_features = review_features.items()\n",
      "        features = [feat[0] for feat in review_features if feat[1] == True]\n",
      "        docData.append((review[1],features))\n",
      "        \n",
      "    \n",
      "    # Classify    \n",
      "    classifier_basic = cl.NaiveBayes(docData)\n",
      "    classifier_log = cl.NaiveBayes(docData, log=True)\n",
      "    classifier_smoothed = cl.NaiveBayes(docData, smoothing=0.5)\n",
      "    classifier_log_smoothed = cl.NaiveBayes(docData, log=True, smoothing=0.5)\n",
      "\n",
      "    \n",
      "    classified_basic = []\n",
      "    classified_log = []\n",
      "    classified_smoothed = []\n",
      "    classified_log_smoothed = []\n",
      "    \n",
      "    tData = [review[0] for review in test_data]\n",
      "    \n",
      "    \n",
      "    for review in tData:\n",
      "        reviewTokenized = nltk.word_tokenize(review)\n",
      "        classified_basic.append(classifier_basic.classify(reviewTokenized, prob=True))\n",
      "        classified_log.append(classifier_log.classify(reviewTokenized, prob = True))\n",
      "        classified_smoothed.append(classifier_smoothed.classify(reviewTokenized, prob = True))\n",
      "        classified_log_smoothed.append(classifier_log_smoothed.classify(reviewTokenized, prob = True))\n",
      "    \n",
      "    # Calculate error metrics using the basic classifier\n",
      "    tTruth = [review[1] for review in test_data]\n",
      "    print pos_adj[0:100]\n",
      "    return  classified_basic, classified_smoothed, tTruth, classifier_basic, classifier_smoothed\n",
      "    \n",
      "   \n",
      "def getMovieData():\n",
      "    \"\"\"\n",
      "    Retrieves the movie review data from nltk.corpus and returns a list of tuples of the form (words_in_review, sentiment)\n",
      "    \"\"\"\n",
      "    movie_data = [(movie_reviews.raw(ID), category) for category in movie_reviews.categories() for ID in movie_reviews.fileids(category)]\n",
      "    return movie_data\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    movie_data = getMovieData()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adjectives = []\n",
      "for trial in range(1,11):\n",
      "    classified_basic, classified_smoothed, tTruth, cl_basic, cl_smoothed = main()\n",
      "    \n",
      "    nPositive = 0\n",
      "    nNegative = 0\n",
      "    nTruePositive = 0\n",
      "    nFalsePositive = 0\n",
      "    nTrueNegative = 0\n",
      "    nFalseNegative = 0\n",
      "    \n",
      "    rindex=0\n",
      "    for review in tTruth:\n",
      "        if review == 'pos':\n",
      "            nPositive+=1\n",
      "            if classified_basic[rindex][0] == 'pos':\n",
      "                nTruePositive+=1\n",
      "            else:\n",
      "                nFalseNegative+=1\n",
      "        else:\n",
      "            nNegative+=1\n",
      "            if classified_basic[rindex][0] == 'pos':\n",
      "                nFalsePositive+=1\n",
      "            else:\n",
      "                nTrueNegative+=1\n",
      "        rindex+=1\n",
      "    \n",
      "        \n",
      "    # SENSITIVITY: True positive rate...positives correctly classified / total positives\n",
      "    basictpRate = float(nTruePositive)/nPositive   \n",
      "    # FALSE ALARM: False positive rate...Negatives incorrectly classified / total negatives\n",
      "    basicfpRate = float(nFalsePositive)/nNegative\n",
      "    # Specificity....1 - fp rate\n",
      "    basicspecificity = float(nTrueNegative)/(nFalsePositive + nTrueNegative)\n",
      "    # Classified_smoothed\n",
      "    nPositive = 0\n",
      "    nNegative = 0\n",
      "    nTruePositive = 0\n",
      "    nFalsePositive = 0\n",
      "    nTrueNegative = 0\n",
      "    nFalseNegative = 0\n",
      "    \n",
      "    # Grab the features and associated probability\n",
      "    features_basic = []\n",
      "    for i in cl_basic.cond_dist.items():\n",
      "        if len(i[1].prob()) == 2:\n",
      "            features_basic.append([(i[0],i[1].prob()[1])])\n",
      "    \n",
      "    \n",
      "    rindex=0\n",
      "    for review in tTruth:\n",
      "        if review == 'pos':\n",
      "            nPositive+=1\n",
      "            if classified_smoothed[rindex][0] == 'pos':\n",
      "                nTruePositive+=1\n",
      "            else:\n",
      "                nFalseNegative+=1\n",
      "        else:\n",
      "            nNegative+=1\n",
      "            if classified_smoothed[rindex][0] == 'pos':\n",
      "                nFalsePositive+=1\n",
      "            else:\n",
      "                nTrueNegative+=1\n",
      "        rindex+=1\n",
      "    \n",
      "        \n",
      "    # SENSITIVITY: True positive rate...positives correctly classified / total positives\n",
      "    smoothtpRate = float(nTruePositive)/nPositive\n",
      "    \n",
      "    # FALSE ALARM: False positive rate...Negatives incorrectly classified / total negatives\n",
      "    smoothfpRate = float(nFalsePositive)/nNegative\n",
      "    # Specificity....1 - fp rate\n",
      "    smoothspecificity = float(nTrueNegative)/(nFalsePositive + nTrueNegative)\n",
      " \n",
      "    features_smooth = []\n",
      "    for i in cl_basic.cond_dist.items():\n",
      "        if len(i[1].prob()) == 2:\n",
      "            features_smooth.append([(i[0],i[1].prob()[1])])\n",
      "            \n",
      "    \n",
      "    adjectives.append([(trial,basictpRate, basicfpRate, basicspecificity, smoothtpRate, smoothfpRate, smoothspecificity, features_basic, features_smooth)])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['able', 'abrasive', 'absolute', 'abusive', 'accessible', 'accomplished', 'accurate', 'acerbic', 'acidic', 'acrobatic', 'acting', 'active', 'actual', 'add', 'additional', 'admirable', 'adorable', 'adrian', 'advanced', 'affair', 'afraid', 'afterglow', 'aged', 'al', 'alcoholic', 'alive', 'alternate', 'ambitious', 'american', 'amusing', 'ancient', 'animal', 'animated', 'annual', 'ant', 'apparent', 'arabian', 'archaic', 'archetypal', 'are', 'arrogant', 'arsenal', 'artistic', 'asian', 'aside', 'athletic', 'attentive', 'attractive', 'atypical', 'aural', 'austrian', 'authentic', 'autobiographical', 'available', 'average', 'aware', 'awful', 'backhanded', 'bad', 'ballistic', 'bandaged', 'bankable', 'bankole', 'basic', 'bearable', 'beast', 'beautiful', 'bed', 'believable', 'believeable', 'belong', 'best', 'betrayal', 'better', 'bible', 'big', 'bigger', 'biggest', 'biopic', 'bird', 'birth', 'bitter', 'bizarre', 'black', 'blast', 'blatant', 'bleached', 'blue', 'blush', 'boastful', 'bogged', 'boisterous']\n",
        "['archer', 'gore', 'honest', 'able', 'above', 'accomplished', 'accountable', 'acting', 'active', 'actual', 'add', 'admirable', 'adrian', 'affair', 'afoul', 'afraid', 'aggressive', 'alive', 'along', 'alternate', 'ambitious', 'american', 'amidst', 'anal', 'animal', 'anonymous', 'apparent', 'appreciative', 'appropriate', 'arbitrary', 'arnold', 'arrive', 'arrogant', 'artificial', 'artistic', 'assistant', 'assorted', 'attractive', 'audacious', 'aural', 'australian', 'authentic', 'autobiographical', 'available', 'aware', 'awful', 'bad', 'banal', 'basic', 'beautiful', 'believable', 'best', 'better', 'betty', 'bible', 'big', 'biggest', 'birth', 'bitter', 'bizarre', 'black', 'blast', 'blind', 'blue', 'boat', 'bold', 'botanical', 'breakfast', 'brian', 'brief', 'bright', 'brilliant', 'brisk', 'british', 'broad', 'broadcast', 'brutal', 'brute', 'bulky', 'burst', 'busy', 'callous', 'capable', 'care', 'cast', 'casual', 'celluloid', 'central', 'cerebral', 'certain', 'character', 'checkmate', 'cheerful', 'cheesy', 'cherished']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['able', 'abrasive', 'absolute', 'abstract', 'accidental', 'acrimonious', 'acting', 'actual', 'acute', 'add', 'admirable', 'affordable', 'african', 'agnostic', 'agreeable', 'air', 'akin', 'alive', 'allied', 'american', 'amphibian', 'amusing', 'analogous', 'angry', 'animal', 'animatronic', 'anthony', 'apocalyptic', 'appear', 'apt', 'arbitrary', 'archaeological', 'arrive', 'arrogant', 'arsenal', 'articulate', 'artistic', 'askew', 'assorted', 'asteroid', 'attractive', 'australian', 'authoritarian', 'available', 'average', 'avid', 'aware', 'awesome', 'awry', 'axiomatic', 'bad', 'barry', 'basic', 'beautiful', 'become', 'behold', 'belfast', 'believable', 'believeable', 'ben', 'best', 'betrayal', 'betsy', 'better', 'bewitched', 'biblical', 'big', 'biggest', 'birth', 'bitter', 'bizarre', 'black', 'blind', 'bloody', 'bonehead', 'boundary', 'brad', 'brady', 'branagh', 'breakthrough', 'breezy', 'brief', 'bright', 'brilliant', 'british', 'broad', 'brutal', 'buffoonish', 'busy']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['able', 'above', 'abrasive', 'absolute', 'absurd', 'academic', 'acceptable', 'accomplished', 'acting', 'actual', 'add', 'admirable', 'adrian', 'affable', 'afraid', 'aghast', 'al', 'albanian', 'alcoholic', 'alive', 'alleged', 'ambitious', 'american', 'amoral', 'amusing', 'angry', 'anniversary', 'annual', 'ant', 'apocalyptic', 'appear', 'appropriate', 'archetypal', 'arrive', 'arrogant', 'arsenal', 'artistic', 'attempted', 'attractive', 'australian', 'automatic', 'available', 'average', 'avoid', 'awful', 'awhile', 'awkward', 'awry', 'backhanded', 'bad', 'ballad', 'bare', 'barlow', 'basic', 'bearable', 'beautiful', 'beer', 'beleivable', 'believable', 'believed', 'belong', 'beside', 'best', 'betsy', 'better', 'big', 'bigger', 'biggest', 'biopic', 'birth', 'bitter', 'black', 'blast', 'blatant', 'bleak', 'blind', 'blue', 'blunt', 'bodacious', 'bonehead', 'bowden', 'bowfinger', 'boy', 'brad', 'break', 'breezy', 'brief', 'bright', 'brilliant', 'british', 'broad', 'brutal', 'calgary', 'canadian', 'capable']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['archer', 'worse', 'able', 'above', 'abrasive', 'absurd', 'abusive', 'accomplished', 'acerbic', 'achievable', 'acting', 'active', 'actual', 'adequate', 'admirable', 'adulterous', 'advanced', 'adventurous', 'aerial', 'afraid', 'agent', 'aggressive', 'agile', 'ahmad', 'al', 'albanian', 'alive', 'alternative', 'ambitious', 'american', 'amidst', 'amoral', 'ample', 'amusing', 'anal', 'analytical', 'andrew', 'angelic', 'anguish', 'animal', 'ant', 'anthony', 'apologetic', 'apoplectic', 'apparent', 'appreciative', 'appropriate', 'articulate', 'aside', 'assistant', 'asteroid', 'asthmatic', 'audacious', 'august', 'authentic', 'autonomous', 'available', 'average', 'aware', 'backpedal', 'bad', 'ballad', 'balletic', 'banal', 'barrymore', 'basic', 'beautiful', 'bed', 'beleiveable', 'belfast', 'believable', 'ben', 'best', 'better', 'bible', 'big', 'bigger', 'biggest', 'biological', 'bird', 'birth', 'bitter', 'bizaare', 'black', 'blatant', 'bleak', 'blind', 'bloody', 'blue', 'blusterous', 'boat', 'bootsy', 'border', 'bowfinger', 'branagh', 'brazillian', 'brian']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['sinister', 'tender', 'able', 'above', 'abusive', 'academic', 'academy', 'accessible', 'accomplished', 'accurate', 'acerbic', 'acting', 'actual', 'add', 'adequate', 'adorable', 'advanced', 'adversary', 'afterglow', 'aggressive', 'agile', 'agreeable', 'alar', 'alien', 'ambitious', 'american', 'amerocentric', 'amiable', 'amoral', 'amusing', 'ancient', 'animal', 'anniversary', 'anymore', 'apologetic', 'apoplectic', 'apparent', 'arrogant', 'articulate', 'artificial', 'artistic', 'artsy', 'asian', 'aside', 'assorted', 'athletic', 'atmospheric', 'attractive', 'atypical', 'authentic', 'available', 'average', 'awful', 'backpedal', 'bad', 'bankable', 'basic', 'beautician', 'beautiful', 'beg', 'began', 'believable', 'believeable', 'belong', 'ben', 'benevolent', 'best', 'betrayal', 'better', 'beverly', 'bible', 'big', 'bigger', 'biggest', 'birth', 'bitter', 'black', 'blind', 'bloated', 'blusterous', 'boastful', 'boat', 'bohemian', 'bold', 'boorish', 'bounteous', 'boy', 'boyish', 'brad', 'breathtaking', 'brian', 'brief', 'bright', 'brilliant', 'british', 'broad']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['scarier', 'able', 'abrasive', 'absolute', 'absurd', 'abusive', 'accidental', 'accomplished', 'acerbic', 'actual', 'additional', 'admirable', 'adorable', 'affair', 'aggressive', 'agreeable', 'al', 'alien', 'alive', 'allied', 'along', 'alternate', 'alternative', 'ambitious', 'american', 'amusing', 'analogous', 'analytical', 'animal', 'animated', 'anniversary', 'ant', 'anthony', 'appropriate', 'arrive', 'aside', 'assertive', 'atmospheric', 'australian', 'authentic', 'autobiographical', 'available', 'aware', 'awful', 'bad', 'bandaged', 'basic', 'bearable', 'beautiful', 'believable', 'believed', 'beloved', 'ben', 'best', 'betsy', 'better', 'bible', 'big', 'bigger', 'biggest', 'bishop', 'black', 'blatant', 'blind', 'blue', 'bowfinger', 'break', 'breakthrough', 'brendan', 'brief', 'bright', 'brilliant', 'british', 'broad', 'broadcast', 'broader', 'brutal', 'brute', 'brutish', 'bunny', 'bureaucratic', 'busy', 'cable', 'caged', 'campy', 'canadian', 'cantonese', 'capable']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['able', 'abrupt', 'absolute', 'abusive', 'acceptable', 'accountable', 'accurate', 'acting', 'actual', 'adequate', 'admirable', 'adorable', 'adventurous', 'affable', 'agreeable', 'akin', 'alive', 'allow', 'along', 'ambiguous', 'american', 'amidst', 'amphibian', 'ample', 'amy', 'ancient', 'andrew', 'angry', 'animal', 'animated', 'annual', 'antarctic', 'anymore', 'apathy', 'apothecary', 'applicable', 'appropriate', 'archetypal', 'arrogant', 'asbury', 'asian', 'aside', 'assertive', 'assorted', 'assured', 'athletic', 'atlantic', 'atrocious', 'attentive', 'attractive', 'atypical', 'australian', 'available', 'average', 'aware', 'awkward', 'awry', 'backhanded', 'bad', 'bare', 'basic', 'beautiful', 'bed', 'believable', 'belong', 'ben', 'benign', 'best', 'better', 'biblical', 'big', 'bigger', 'biggest', 'biopic', 'birth', 'bitter', 'bizarre', 'black', 'bleak', 'blind', 'bloody', 'blue', 'bobby', 'bold', 'bowfinger', 'branagh', 'brash', 'breakthrough', 'breathtaking', 'brian', 'brief', 'bright', 'brilliant', 'british', 'broad']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['able', 'abrupt', 'absurd', 'accessible', 'accidental', 'accurate', 'acrylic', 'acting', 'active', 'actual', 'additional', 'adjective', 'admirable', 'adventurous', 'advocate', 'aesthetic', 'afraid', 'african', 'agent', 'agreeable', 'alien', 'alive', 'allegorical', 'allow', 'aloft', 'alternate', 'amateurish', 'ambiguous', 'ambitious', 'ambrose', 'american', 'amidst', 'amusing', 'andrew', 'angelic', 'anguish', 'annette', 'anniversary', 'annual', 'antiseptic', 'anxious', 'anymore', 'apparent', 'appreciate', 'appropriate', 'arbitrary', 'arranged', 'arrive', 'arrogant', 'artificial', 'artistic', 'aside', 'askew', 'asshole', 'atlantic', 'atmosphere', 'attentive', 'attractive', 'australian', 'austrian', 'authentic', 'autobiographical', 'available', 'average', 'aware', 'bad', 'baffled', 'bare', 'barry', 'basic', 'beautiful', 'become', 'belfast', 'believable', 'believeable', 'best', 'better', 'bible', 'biblical', 'big', 'biggest', 'bitter', 'black', 'blair', 'boat', 'bowling', 'brad', 'breakthrough', 'breathtaking', 'breezy', 'brendan', 'brian', 'brief', 'brilliant', 'british', 'broad']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['carter', 'worse', 'able', 'abrasive', 'absurd', 'abusive', 'accessible', 'accomplished', 'accurate', 'acidic', 'acting', 'actual', 'additional', 'adequate', 'adjective', 'adrian', 'aerial', 'affair', 'afraid', 'african', 'aggressive', 'agreeable', 'al', 'alferd', 'alive', 'ambitious', 'american', 'amiable', 'angry', 'animated', 'annual', 'apparent', 'archival', 'arctic', 'arduous', 'artistic', 'askew', 'assistant', 'attainable', 'attentive', 'attic', 'aural', 'australian', 'autobiographical', 'available', 'average', 'aware', 'awful', 'awhile', 'bad', 'banal', 'basic', 'bearish', 'beautiful', 'belfast', 'belgian', 'believable', 'belong', 'ben', 'best', 'bette', 'better', 'betty', 'bible', 'big', 'bigger', 'biggest', 'biopic', 'bitter', 'bizarre', 'black', 'blue', 'boat', 'bored', 'bother', 'bowfinger', 'boyle', 'branagh', 'break', 'breathtaking', 'brian', 'brief', 'bright', 'brilliant', 'broad', 'brush', 'bunny', 'busy', 'cable', 'canadian', 'cannibal', 'capable', 'careful']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('adjectives.txt','w') as file:\n",
      "    for item in adjectives:\n",
      "        print>>file, item\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
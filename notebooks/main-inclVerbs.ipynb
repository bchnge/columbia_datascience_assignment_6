{
 "metadata": {
  "name": "main-inclVerbs"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import movie_reviews\n",
      "import nltk\n",
      "import random\n",
      "\n",
      "from homework_06.src.tagger import document_features\n",
      "import homework_06.src.classifier as cl\n",
      "import homework_06.src.tagger as tg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main():\n",
      "    #get the movie data\n",
      "    movie_data = getMovieData()\n",
      "    #shuffle it up\n",
      "    random.shuffle(movie_data)\n",
      "    #break up into test and train\n",
      "    test_data, train_data = movie_data[:len(movie_data)/2],  movie_data[len(movie_data)/2:]\n",
      "\n",
      "\n",
      "    #####From here on it's up to you how you want to tag and classify the reviews\n",
      "\n",
      "      # First, determine set of words to use for features. Consider using getTopwords\n",
      "    \n",
      "    pos_reviews = [sent[0] for sent in train_data if sent[1]=='pos']\n",
      "    neg_reviews = [sent[0] for sent in train_data if sent[1]=='neg']\n",
      "    \n",
      "    # Take out all adjectives and verb\n",
      "    tagged_pos = tg.posTagger(pos_reviews[0:25], pos_type = 'JJ')\n",
      "    tagged_pos_verbs = tg.posTagger(pos_reviews[0:25], pos_type = 'V')\n",
      "    tagged_pos = list(set(tagged_pos).union(set(tagged_pos_verbs)))\n",
      "    \n",
      "    tagged_neg = tg.posTagger(neg_reviews[0:25], pos_type = 'JJ')\n",
      "    tagged_neg_verbs = tg.posTagger(neg_reviews[0:25], pos_type = 'V')\n",
      "    tagged_neg = list(set(tagged_neg).union(set(tagged_neg_verbs))) \n",
      "    \n",
      "    pos_adj = [tag[0] for tag in tagged_pos]\n",
      "    neg_adj = [tag[0] for tag in tagged_neg]\n",
      "    \n",
      "    pos_adj = tg.getTopWords(pos_adj,0.05)\n",
      "    neg_adj = tg.getTopWords(neg_adj,0.05)\n",
      "    \n",
      "    tagged_pos_final = [tag for tag in tagged_pos if tag[0] in pos_adj]\n",
      "    tagged_neg_final = [tag for tag in tagged_neg if tag[0] in neg_adj]\n",
      "    \n",
      "    tagged_features = list(set(tagged_pos_final).union(set(tagged_neg_final))) \n",
      "    tagged_features = list(set(tagged_features))\n",
      "    \n",
      "        \n",
      "    docData = []\n",
      "    for review in train_data:\n",
      "        review_features = document_features(review[0], tagged_features)\n",
      "        review_features = review_features.items()\n",
      "        features = [feat[0] for feat in review_features if feat[1] == True]\n",
      "        docData.append((review[1],features))\n",
      "        \n",
      "    \n",
      "    # Classify    \n",
      "    classifier_basic = cl.NaiveBayes(docData)\n",
      "    classifier_log = cl.NaiveBayes(docData, log=True)\n",
      "    classifier_smoothed = cl.NaiveBayes(docData, smoothing=0.5)\n",
      "    classifier_log_smoothed = cl.NaiveBayes(docData, log=True, smoothing=0.5)\n",
      "\n",
      "\n",
      "    classified_basic = []\n",
      "    classified_log = []\n",
      "    classified_smoothed = []\n",
      "    classified_log_smoothed = []\n",
      "    \n",
      "    tData = [review[0] for review in test_data]\n",
      "    \n",
      "    \n",
      "    for review in tData:\n",
      "        reviewTokenized = nltk.word_tokenize(review)\n",
      "        classified_basic.append(classifier_basic.classify(reviewTokenized, prob=True))\n",
      "        classified_log.append(classifier_log.classify(reviewTokenized, prob = True))\n",
      "        classified_smoothed.append(classifier_smoothed.classify(reviewTokenized, prob = True))\n",
      "        classified_log_smoothed.append(classifier_log_smoothed.classify(reviewTokenized, prob = True))\n",
      "    \n",
      "    # Calculate error metrics using the basic classifier\n",
      "    tTruth = [review[1] for review in test_data]\n",
      "    \n",
      "    return  classified_basic, classified_smoothed, tTruth, classifier_basic, classifier_smoothed\n",
      "    \n",
      "   \n",
      "def getMovieData():\n",
      "    \"\"\"\n",
      "    Retrieves the movie review data from nltk.corpus and returns a list of tuples of the form (words_in_review, sentiment)\n",
      "    \"\"\"\n",
      "    movie_data = [(movie_reviews.raw(ID), category) for category in movie_reviews.categories() for ID in movie_reviews.fileids(category)]\n",
      "    return movie_data\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    movie_data = getMovieData()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verbs = []\n",
      "for trial in range(1,11):\n",
      "    classified_basic, classified_smoothed, tTruth, cl_basic, cl_smoothed = main()\n",
      "    \n",
      "    nPositive = 0\n",
      "    nNegative = 0\n",
      "    nTruePositive = 0\n",
      "    nFalsePositive = 0\n",
      "    nTrueNegative = 0\n",
      "    nFalseNegative = 0\n",
      "    \n",
      "    rindex=0\n",
      "    for review in tTruth:\n",
      "        if review == 'pos':\n",
      "            nPositive+=1\n",
      "            if classified_basic[rindex][0] == 'pos':\n",
      "                nTruePositive+=1\n",
      "            else:\n",
      "                nFalseNegative+=1\n",
      "        else:\n",
      "            nNegative+=1\n",
      "            if classified_basic[rindex][0] == 'pos':\n",
      "                nFalsePositive+=1\n",
      "            else:\n",
      "                nTrueNegative+=1\n",
      "        rindex+=1\n",
      "    \n",
      "        \n",
      "    # SENSITIVITY: True positive rate...positives correctly classified / total positives\n",
      "    basictpRate = float(nTruePositive)/nPositive   \n",
      "    # FALSE ALARM: False positive rate...Negatives incorrectly classified / total negatives\n",
      "    basicfpRate = float(nFalsePositive)/nNegative\n",
      "    # Specificity....1 - fp rate\n",
      "    basicspecificity = float(nTrueNegative)/(nFalsePositive + nTrueNegative)\n",
      "    # Classified_smoothed\n",
      "    nPositive = 0\n",
      "    nNegative = 0\n",
      "    nTruePositive = 0\n",
      "    nFalsePositive = 0\n",
      "    nTrueNegative = 0\n",
      "    nFalseNegative = 0\n",
      "    \n",
      "    # Grab the features and associated probability\n",
      "    features_basic = []\n",
      "    for i in cl_basic.cond_dist.items():\n",
      "        if len(i[1].prob()) == 2:\n",
      "            features_basic.append([(i[0],i[1].prob()[1])])\n",
      "    \n",
      "    \n",
      "    rindex=0\n",
      "    for review in tTruth:\n",
      "        if review == 'pos':\n",
      "            nPositive+=1\n",
      "            if classified_smoothed[rindex][0] == 'pos':\n",
      "                nTruePositive+=1\n",
      "            else:\n",
      "                nFalseNegative+=1\n",
      "        else:\n",
      "            nNegative+=1\n",
      "            if classified_smoothed[rindex][0] == 'pos':\n",
      "                nFalsePositive+=1\n",
      "            else:\n",
      "                nTrueNegative+=1\n",
      "        rindex+=1\n",
      "    \n",
      "        \n",
      "    # SENSITIVITY: True positive rate...positives correctly classified / total positives\n",
      "    smoothtpRate = float(nTruePositive)/nPositive\n",
      "    \n",
      "    # FALSE ALARM: False positive rate...Negatives incorrectly classified / total negatives\n",
      "    smoothfpRate = float(nFalsePositive)/nNegative\n",
      "    # Specificity....1 - fp rate\n",
      "    smoothspecificity = float(nTrueNegative)/(nFalsePositive + nTrueNegative)\n",
      " \n",
      "    features_smooth = []\n",
      "    for i in cl_basic.cond_dist.items():\n",
      "        if len(i[1].prob()) == 2:\n",
      "            features_smooth.append([(i[0],i[1].prob()[1])])\n",
      "            \n",
      "    \n",
      "    verbs.append([(trial,basictpRate, basicfpRate, basicspecificity, smoothtpRate, smoothfpRate, smoothspecificity, features_basic, features_smooth)])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('AdjectivesVerbs.txt','w') as file:\n",
      "    for item in verbs:\n",
      "        print>>file, item\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}